{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit\n",
        "import torch\n",
        "print(torch.__version__)  # 2.4.0+cu121\n",
        "!pip install torch-geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8lU1-dVhFyf",
        "outputId": "45194a06-5cdb-401a-8d4d-dc0c22729782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (2024.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "2.5.1+cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu121.html\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_scatter-2.1.2%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_sparse-0.6.18%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1 torch-scatter-2.1.2+pt25cu121 torch-sparse-0.6.18+pt25cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeHMdt1JXhiK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/volkamerlab/EDSAI_CADD_intro/refs/heads/main/data/solubility.csv\")\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RgSCH6mJercI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import from_smiles\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "def process_smiles(row):\n",
        "    data = from_smiles(row.SMILES)\n",
        "    data.x = data.x.to(torch.float)\n",
        "    data.y = torch.tensor(row.Solubility, dtype=torch.float)\n",
        "    return data\n",
        "\n",
        "train_dataloader = DataLoader(list(map(process_smiles, df_train.itertuples())), batch_size=32, shuffle=True)\n",
        "valid_dataloader = DataLoader(list(map(process_smiles, df_val.itertuples())), batch_size=32)\n",
        "test_dataloader = DataLoader(list(map(process_smiles, df_test.itertuples())), batch_size=32)"
      ],
      "metadata": {
        "id": "cgs9Oj_idBND"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import global_mean_pool, GCNConv\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as Fun\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU\n",
        "\n",
        "from torch_geometric.nn import GCNConv, GINConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "import torch.nn.functional as Fun\n",
        "\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    \"\"\"Graph Isomorphism Network class with 3 GINConv layers and 2 linear layers\"\"\"\n",
        "\n",
        "    def __init__(self, dim_h):\n",
        "        \"\"\"Initializing GIN class\n",
        "\n",
        "        Args:\n",
        "            dim_h (int): the dimension of hidden layers\n",
        "        \"\"\"\n",
        "        super(GIN, self).__init__()\n",
        "\n",
        "        self.conv1 = GINConv(\n",
        "            Sequential(Linear(9, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU())\n",
        "        )\n",
        "        self.conv2 = GINConv(\n",
        "            Sequential(\n",
        "                Linear(dim_h, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
        "            )\n",
        "        )\n",
        "        self.conv3 = GINConv(\n",
        "            Sequential(\n",
        "                Linear(dim_h, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.lin1 = Linear(dim_h, dim_h)\n",
        "        self.lin2 = Linear(dim_h, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        edge_index = data.edge_index\n",
        "        batch = data.batch\n",
        "\n",
        "        # Node embeddings\n",
        "        h = self.conv1(x, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv2(h, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv3(h, edge_index)\n",
        "\n",
        "        # Graph-level readout\n",
        "        h = global_add_pool(h, batch)\n",
        "\n",
        "        h = self.lin1(h)\n",
        "        h = h.relu()\n",
        "        h = Fun.dropout(h, p=0.1, training=self.training)\n",
        "        h = self.lin2(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "model = GIN(32)\n",
        "model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "def train_step(loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out.squeeze(), data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_dataloader.dataset)\n",
        "\n",
        "def test_step(loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        out = model(data)\n",
        "        loss = criterion(out.squeeze(), data.y)\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "train_losses, valid_losses = list(), list()\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_step(train_dataloader)\n",
        "    valid_loss = test_step(valid_dataloader)\n",
        "\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:03d}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')"
      ],
      "metadata": {
        "id": "vo1nm9OCdNG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e107e5-2af9-44b8-afe5-3413fb9eaed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Loss: 4.2744, Validation Loss: 3.4909\n",
            "Epoch: 002, Train Loss: 4.0231, Validation Loss: 3.5483\n",
            "Epoch: 003, Train Loss: 3.6402, Validation Loss: 3.5977\n",
            "Epoch: 004, Train Loss: 3.2996, Validation Loss: 3.2183\n",
            "Epoch: 005, Train Loss: 3.1952, Validation Loss: 2.8149\n",
            "Epoch: 006, Train Loss: 3.3809, Validation Loss: 3.2839\n",
            "Epoch: 007, Train Loss: 3.4329, Validation Loss: 3.2354\n",
            "Epoch: 008, Train Loss: 3.2913, Validation Loss: 3.2036\n",
            "Epoch: 009, Train Loss: 2.9337, Validation Loss: 3.0710\n",
            "Epoch: 010, Train Loss: 2.9070, Validation Loss: 2.6792\n",
            "Epoch: 011, Train Loss: 3.2020, Validation Loss: 3.3337\n",
            "Epoch: 012, Train Loss: 3.3572, Validation Loss: 3.0625\n",
            "Epoch: 013, Train Loss: 3.1666, Validation Loss: 2.6658\n",
            "Epoch: 014, Train Loss: 2.7807, Validation Loss: 2.4710\n",
            "Epoch: 015, Train Loss: 2.8841, Validation Loss: 3.7423\n",
            "Epoch: 016, Train Loss: 3.4481, Validation Loss: 3.3935\n",
            "Epoch: 017, Train Loss: 3.3739, Validation Loss: 3.5376\n",
            "Epoch: 018, Train Loss: 3.5955, Validation Loss: 3.3001\n",
            "Epoch: 019, Train Loss: 3.1315, Validation Loss: 3.0015\n",
            "Epoch: 020, Train Loss: 2.9822, Validation Loss: 2.7620\n",
            "Epoch: 021, Train Loss: 2.9458, Validation Loss: 3.1568\n",
            "Epoch: 022, Train Loss: 3.2061, Validation Loss: 2.8375\n",
            "Epoch: 023, Train Loss: 3.1025, Validation Loss: 3.0506\n",
            "Epoch: 024, Train Loss: 2.9221, Validation Loss: 2.6635\n",
            "Epoch: 025, Train Loss: 2.6249, Validation Loss: 2.5189\n",
            "Epoch: 026, Train Loss: 3.0641, Validation Loss: 3.1834\n",
            "Epoch: 027, Train Loss: 3.1531, Validation Loss: 3.0129\n",
            "Epoch: 028, Train Loss: 2.9346, Validation Loss: 2.7850\n",
            "Epoch: 029, Train Loss: 2.6823, Validation Loss: 2.5073\n",
            "Epoch: 030, Train Loss: 2.6373, Validation Loss: 2.4676\n",
            "Epoch: 031, Train Loss: 2.4646, Validation Loss: 2.3714\n",
            "Epoch: 032, Train Loss: 2.4240, Validation Loss: 2.2293\n",
            "Epoch: 033, Train Loss: 2.3842, Validation Loss: 2.2660\n"
          ]
        }
      ]
    }
  ]
}